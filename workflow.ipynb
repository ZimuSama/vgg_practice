{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VGG11 frist for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import vgg\n",
    "from script.function import train, test, save\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Set random_seed and environment parameters\n",
    "#################################################################\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "#################################################################\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize model\n",
    "#################################################################\n",
    "# weight_path = './weights/vgg19.pt'\n",
    "image_size = 224\n",
    "classes_num = 15\n",
    "model = vgg.NeuralNetwork(type = 'A', classes = classes_num).to(device)\n",
    "# state_dict = torch.load(weight_path,map_location=device)\n",
    "# model.load_state_dict(state_dict, strict = False)\n",
    "\n",
    "# Set hyper-parameters\n",
    "#################################################################\n",
    "# opt = torch.optim.RMSprop(model.parameters(), lr = 1e-4)\n",
    "lr = 1e-2\n",
    "opt = torch.optim.SGD(model.parameters(), lr = lr, momentum = 0.9, weight_decay = 5e-4)\n",
    "loss_func = nn.functional.cross_entropy\n",
    "metric_func = lambda x,y:torchmetrics.functional.accuracy(x, y, task=\"multiclass\", num_classes=classes_num)\n",
    "metric_name = \"accuracy\"\n",
    "\n",
    "# Construct dataset\n",
    "#################################################################\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize([image_size, image_size]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(degrees=45),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "#     transforms.GaussianBlur([3, 3], sigma=(0.1, 4.0)),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize([image_size, image_size]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# base_dir = './imagenet-object-localization-challenge/ILSVRC/Data/ILSVRC/'\n",
    "base_dir = './data/15classes/'\n",
    "train_path = base_dir+'train/'\n",
    "val_path = base_dir+'test/'\n",
    "batch_size = 64\n",
    "train_data = datasets.ImageFolder(train_path, transform=transforms_train)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=6, prefetch_factor = 5)\n",
    "\n",
    "val_data = datasets.ImageFolder(val_path, transform=transforms_val)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Start to train model\n",
    "#################################################################\n",
    "epochs = 200\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "loss=[]\n",
    "val_loss=[]\n",
    "count = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n------------------------------------\")\n",
    "    start = time.time()\n",
    "    a,b = train(train_loader, model, loss_func, metric_func, opt, device)\n",
    "    end = time.time()\n",
    "    print(str(datetime.timedelta(seconds=int(round((end - start))))))\n",
    "    acc.append(a)\n",
    "    loss.append(b)\n",
    "    start = time.time()\n",
    "    a,b = test(val_loader, model, loss_func, metric_func, device)\n",
    "    end = time.time()\n",
    "    print(str(datetime.timedelta(seconds=int(round((end - start))))))\n",
    "    val_acc.append(a)\n",
    "    val_loss.append(b)\n",
    "    print(f\"------------------------------------\\n\")\n",
    "    if count < 10:\n",
    "        count += 1\n",
    "        continue\n",
    "    if np.mean(acc[t-9:t+1]) > 0.9 and np.mean(acc[t-4:t+1]) - np.mean(acc[t-9:t-4]) < 0.001:\n",
    "        break\n",
    "    if np.mean(val_acc[t-4:t+1]) <= np.mean(val_acc[t-9:t-4]):\n",
    "        lr /= 10\n",
    "        opt = torch.optim.SGD(model.parameters(), lr = lr, momentum = 0.9, weight_decay = 5e-4)\n",
    "        print('Learning rate adjusted to', lr)\n",
    "        count = 0\n",
    "    save(model,'./weights/vgg11_checkpoint.pt')\n",
    "print(\"Done!\")\n",
    "\n",
    "# Plot\n",
    "#################################################################\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "save(model,'./weights/vgg11_full.pt')\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize VGG19 using pre-trained VGG11's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import vgg\n",
    "from script.function import train, test, save\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Set random_seed and environment parameters\n",
    "#################################################################\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "#################################################################\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize model\n",
    "#################################################################\n",
    "weight_path = './weights/vgg11_full.pt'\n",
    "image_size = 224\n",
    "classes_num = 15\n",
    "model = vgg.NeuralNetwork(type = 'E', classes = classes_num).to(device)\n",
    "state_dict = torch.load(weight_path,map_location=device)\n",
    "model.load_state_dict(state_dict, strict = False)\n",
    "\n",
    "# Set hyper-parameters\n",
    "#################################################################\n",
    "# opt = torch.optim.RMSprop(model.parameters(), lr = 1e-4)\n",
    "lr = 1e-2\n",
    "opt = torch.optim.SGD(model.parameters(), lr = lr, momentum = 0.9, weight_decay = 5e-4)\n",
    "loss_func = nn.functional.cross_entropy\n",
    "metric_func = lambda x,y:torchmetrics.functional.accuracy(x, y, task=\"multiclass\", num_classes=classes_num)\n",
    "metric_name = \"accuracy\"\n",
    "\n",
    "# Construct dataset\n",
    "#################################################################\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize([image_size, image_size]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(degrees=45),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "#     transforms.GaussianBlur([3, 3], sigma=(0.1, 3.0)),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize([image_size, image_size]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "base_dir = './data/15classes/'\n",
    "train_path = base_dir+'train/'\n",
    "val_path = base_dir+'test/'\n",
    "batch_size = 32\n",
    "train_data = datasets.ImageFolder(train_path, transform=transforms_train)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=6, prefetch_factor = 5)\n",
    "\n",
    "val_data = datasets.ImageFolder(val_path, transform=transforms_val)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Start to train model\n",
    "#################################################################\n",
    "epochs = 300\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "loss=[]\n",
    "val_loss=[]\n",
    "count = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n------------------------------------\")\n",
    "    start = time.time()\n",
    "    a,b = train(train_loader, model, loss_func, metric_func, opt, device)\n",
    "    end = time.time()\n",
    "    print(str(datetime.timedelta(seconds=int(round((end - start))))))\n",
    "    acc.append(a)\n",
    "    loss.append(b)\n",
    "    start = time.time()\n",
    "    a,b = test(val_loader, model, loss_func, metric_func, device)\n",
    "    end = time.time()\n",
    "    print(str(datetime.timedelta(seconds=int(round((end - start))))))\n",
    "    val_acc.append(a)\n",
    "    val_loss.append(b)\n",
    "    print(f\"------------------------------------\\n\")\n",
    "    if count <= 10:\n",
    "        count += 1\n",
    "        continue\n",
    "    if np.mean(acc[t-9:t+1]) > 0.9 and np.mean(acc[t-4:t+1]) - np.mean(acc[t-9:t-4]) < 0.001:\n",
    "        break\n",
    "    if np.mean(val_acc[t-4:t+1]) <= np.mean(val_acc[t-9:t-4]):\n",
    "        lr /= 10\n",
    "        opt = torch.optim.SGD(model.parameters(), lr = lr, momentum = 0.9, weight_decay = 5e-4)\n",
    "        print('Learning rate adjusted to', lr)\n",
    "        count = 0\n",
    "    save(model,'./weights/vgg19_checkpoint.pt')\n",
    "print(\"Done!\")\n",
    "\n",
    "# Plot\n",
    "#################################################################\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "save(model,'./weights/vgg19_full.pt')\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
